{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "activated-format",
   "metadata": {},
   "source": [
    "# Tensors and Tensor Arithmetic\n",
    "\n",
    "In deep learning it is common to see a lot of discussion around tensors as the cornerstone data structure. Tensor even appears in name of Google's flagship machine learning library:TensorFlow. Tensors are a type of data structure used in linear algebra, and like vectors and matrices, you can calculate arithmetic operations with tensors.\n",
    "\n",
    "## What are Tensors\n",
    "\n",
    "A tensor is a generalization of vectors and matrices and is easily understood as a multidimensional array.\n",
    "\n",
    "**Note: In the general case, an array of numbers arranged on a regular grid with a variable number of axes is known as a tensor.**\n",
    "\n",
    "A vector is a one-dimensional or first order tensor and a matrix is a two-dimensional or second order tensor. Tensor notation is much like matrix notation with a capital letter representing a tensor and lowercase letters with subscript integers representing scalar values within the tensor. For example, below defines a 3 x 3 x 3 three-dimensional tensor T with dimensions index as $t_{i,j,k}$.\n",
    "\n",
    "$$\\begin{aligned}\n",
    "T = \\begin{pmatrix}\n",
    "t_{1,1,1}\\; t_{1,2,1}\\; t_{1,3,1}\\\\\n",
    "t_{2,1,1}\\; t_{2,2,1}\\; t_{2,3,1}\\\\\n",
    "t_{3,1,1}\\; t_{3,2,1}\\; t_{3,3,1}\n",
    "\\end{pmatrix}\n",
    ",\n",
    "\\begin{pmatrix}\n",
    "t_{1,1,2}\\; t_{1,2,2}\\; t_{1,3,2}\\\\\n",
    "t_{2,1,2}\\; t_{2,2,2}\\; t_{2,3,2}\\\\\n",
    "t_{3,1,2}\\; t_{3,2,2}\\; t_{3,3,2}\n",
    "\\end{pmatrix}\n",
    ",\n",
    "\\begin{pmatrix}\n",
    "t_{1,1,3}\\; t_{1,2,3}\\; t_{1,3,3}\\\\\n",
    "t_{2,1,3}\\; t_{2,2,3}\\; t_{2,3,3}\\\\\n",
    "t_{3,1,3}\\; t_{3,2,3}\\; t_{3,3,3}\n",
    "\\end{pmatrix}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Many of the operations that can be performed with scalars, vectors, and matrices can be reformulated to be performed with tensors. As a tool, tensors and tensor algebra is widely used in the fields of physics and engineering. Some operations in machine learning such as the training and operation of deep learning models can be described in terms of tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secondary-generator",
   "metadata": {},
   "source": [
    "## Tensors in Python\n",
    "\n",
    "Like vectors and matrices, tensors can be represented in Python using the N-dimensional array (ndarray). A tensor can be defined in-line to the constructor of **array()** as a list of lists. The example below defines a 3 x 3 x 3 tensor as a NumPy ndarray. Three dimensions is easier to wrap your head around. Here, we first define rows, then a list of rows stacked as columns, then a list of columns stacked as levels in a cube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "exclusive-combine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 3)\n",
      "[[[ 1  2  3]\n",
      "  [ 4  5  6]\n",
      "  [ 7  8  9]]\n",
      "\n",
      " [[11 12 13]\n",
      "  [14 15 16]\n",
      "  [17 18 19]]\n",
      "\n",
      " [[21 22 23]\n",
      "  [24 25 26]\n",
      "  [27 28 29]]]\n"
     ]
    }
   ],
   "source": [
    "# create tensor\n",
    "from numpy import array\n",
    "T = array([\n",
    "[[1,2,3], [4,5,6], [7,8,9]],\n",
    "[[11,12,13], [14,15,16], [17,18,19]],\n",
    "[[21,22,23], [24,25,26], [27,28,29]]])\n",
    "print(T.shape)\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-prediction",
   "metadata": {},
   "source": [
    "## Tensor Arithmetic\n",
    "\n",
    "As with matrices, we can perform element-wise arithmetic between tensors. In this section, we will work through the four main arithmetic operations.\n",
    "\n",
    "### Tensor Addition\n",
    "\n",
    "The element-wise addition of two tensors with the same dimensions results in a new tensor with the same dimensions where each scalar value is the element-wise addition of the scalars in the parent tensors.\n",
    "\n",
    "$$\\begin{aligned}\n",
    "A = \\begin{pmatrix}\n",
    "a_{1,1,1}\\; a_{1,2,1}\\; a_{1,3,1}\\\\\n",
    "a_{2,1,1}\\; a_{2,2,1}\\; a_{2,3,1}\n",
    "\\end{pmatrix}\n",
    ",\n",
    "\\begin{pmatrix}\n",
    "a_{1,1,2}\\; a_{1,2,2}\\; a_{1,3,2}\\\\\n",
    "a_{2,1,2}\\; a_{2,2,2}\\; a_{2,3,2}\n",
    "\\end{pmatrix}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "$$\\begin{aligned}\n",
    "B = \\begin{pmatrix}\n",
    "b_{1,1,1}\\; b_{1,2,1}\\; b_{1,3,1}\\\\\n",
    "b_{2,1,1}\\; b_{2,2,1}\\; b_{2,3,1}\n",
    "\\end{pmatrix}\n",
    ",\n",
    "\\begin{pmatrix}\n",
    "b_{1,1,2}\\; b_{1,2,2}\\; b_{1,3,2}\\\\\n",
    "b_{2,1,2}\\; b_{2,2,2}\\; b_{2,3,2}\n",
    "\\end{pmatrix}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "$$C = A + B$$\n",
    "\n",
    "$$\\begin{aligned}\n",
    "C = \\begin{pmatrix}\n",
    "a_{1,1,1}+b_{1,1,1}\\; a_{1,2,1}+b_{1,2,1}\\; a_{1,3,1}+b_{1,3,1}\\\\\n",
    "a_{2,1,1}+b_{2,1,1}\\; a_{2,2,1}+b_{2,2,1}\\; a_{2,3,1}+b_{2,3,1}\n",
    "\\end{pmatrix}\n",
    ",\n",
    "\\begin{pmatrix}\n",
    "a_{1,1,2}+b_{1,1,2}\\; a_{1,2,2}+b_{1,2,2}\\; a_{1,3,2}+b_{1,3,2}\\\\\n",
    "a_{2,1,2}+b_{2,1,2}\\; a_{2,2,2}+b_{2,2,2}\\; a_{2,3,2}+b_{2,3,2}\n",
    "\\end{pmatrix}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "In NumPy, we can add tensors directly by adding arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "earned-diameter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 2  4  6]\n",
      "  [ 8 10 12]\n",
      "  [14 16 18]]\n",
      "\n",
      " [[22 24 26]\n",
      "  [28 30 32]\n",
      "  [34 36 38]]\n",
      "\n",
      " [[42 44 46]\n",
      "  [48 50 52]\n",
      "  [54 56 58]]]\n"
     ]
    }
   ],
   "source": [
    "# tensor addition\n",
    "from numpy import array\n",
    "\n",
    "# define first tensor\n",
    "A = array([\n",
    "[[1,2,3], [4,5,6], [7,8,9]],\n",
    "[[11,12,13], [14,15,16], [17,18,19]],\n",
    "[[21,22,23], [24,25,26], [27,28,29]]])\n",
    "\n",
    "# define second tensor\n",
    "B = array([\n",
    "[[1,2,3], [4,5,6], [7,8,9]],\n",
    "[[11,12,13], [14,15,16], [17,18,19]],\n",
    "[[21,22,23], [24,25,26], [27,28,29]]])\n",
    "\n",
    "# add tensors\n",
    "C = A + B\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latter-headquarters",
   "metadata": {},
   "source": [
    "### Tensor Subtraction\n",
    "\n",
    "The element-wise subtraction of one tensor from another tensor with the same dimensions results in a new tensor with the same dimensions where each scalar value is the element-wise subtraction of the scalars in the parent tensors.\n",
    "\n",
    "$$\\begin{aligned}\n",
    "A = \\begin{pmatrix}\n",
    "a_{1,1,1}\\; a_{1,2,1}\\; a_{1,3,1}\\\\\n",
    "a_{2,1,1}\\; a_{2,2,1}\\; a_{2,3,1}\n",
    "\\end{pmatrix}\n",
    ",\n",
    "\\begin{pmatrix}\n",
    "a_{1,1,2}\\; a_{1,2,2}\\; a_{1,3,2}\\\\\n",
    "a_{2,1,2}\\; a_{2,2,2}\\; a_{2,3,2}\n",
    "\\end{pmatrix}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "$$\\begin{aligned}\n",
    "B = \\begin{pmatrix}\n",
    "b_{1,1,1}\\; b_{1,2,1}\\; b_{1,3,1}\\\\\n",
    "b_{2,1,1}\\; b_{2,2,1}\\; b_{2,3,1}\n",
    "\\end{pmatrix}\n",
    ",\n",
    "\\begin{pmatrix}\n",
    "b_{1,1,2}\\; b_{1,2,2}\\; b_{1,3,2}\\\\\n",
    "b_{2,1,2}\\; b_{2,2,2}\\; b_{2,3,2}\n",
    "\\end{pmatrix}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "$$C = A - B$$\n",
    "\n",
    "$$\\begin{aligned}\n",
    "C = \\begin{pmatrix}\n",
    "a_{1,1,1}-b_{1,1,1}\\; a_{1,2,1}-b_{1,2,1}\\; a_{1,3,1}-b_{1,3,1}\\\\\n",
    "a_{2,1,1}-b_{2,1,1}\\; a_{2,2,1}-b_{2,2,1}\\; a_{2,3,1}-b_{2,3,1}\n",
    "\\end{pmatrix}\n",
    ",\n",
    "\\begin{pmatrix}\n",
    "a_{1,1,2}-b_{1,1,2}\\; a_{1,2,2}-b_{1,2,2}\\; a_{1,3,2}-b_{1,3,2}\\\\\n",
    "a_{2,1,2}-b_{2,1,2}\\; a_{2,2,2}-b_{2,2,2}\\; a_{2,3,2}-b_{2,3,2}\n",
    "\\end{pmatrix}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "In NumPy, we can subtract tensors directly by subtracting arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "consistent-announcement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]]\n"
     ]
    }
   ],
   "source": [
    "# tensor subtraction\n",
    "from numpy import array\n",
    "\n",
    "# define first tensor\n",
    "A = array([\n",
    "[[1,2,3], [4,5,6], [7,8,9]],\n",
    "[[11,12,13], [14,15,16], [17,18,19]],\n",
    "[[21,22,23], [24,25,26], [27,28,29]]])\n",
    "\n",
    "# define second tensor\n",
    "B = array([\n",
    "[[1,2,3], [4,5,6], [7,8,9]],\n",
    "[[11,12,13], [14,15,16], [17,18,19]],\n",
    "[[21,22,23], [24,25,26], [27,28,29]]])\n",
    "\n",
    "# subtract tensors\n",
    "C = A - B\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floppy-romania",
   "metadata": {},
   "source": [
    "### Tensor Hadamard Product\n",
    "\n",
    "The element-wise multiplication of one tensor with another tensor with the same dimensions results in a new tensor with the same dimensions where each scalar value is the element-wise multiplication of the scalars in the parent tensors. As with matrices, the operation is referred to as the Hadamard Product to differentiate it from tensor multiplication. Here, we will use the **$\\cdot$** operator to indicate the Hadamard product operation between tensors.\n",
    "\n",
    "$$\\begin{aligned}\n",
    "A = \\begin{pmatrix}\n",
    "a_{1,1,1}\\; a_{1,2,1}\\; a_{1,3,1}\\\\\n",
    "a_{2,1,1}\\; a_{2,2,1}\\; a_{2,3,1}\n",
    "\\end{pmatrix}\n",
    ",\n",
    "\\begin{pmatrix}\n",
    "a_{1,1,2}\\; a_{1,2,2}\\; a_{1,3,2}\\\\\n",
    "a_{2,1,2}\\; a_{2,2,2}\\; a_{2,3,2}\n",
    "\\end{pmatrix}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "$$\\begin{aligned}\n",
    "B = \\begin{pmatrix}\n",
    "b_{1,1,1}\\; b_{1,2,1}\\; b_{1,3,1}\\\\\n",
    "b_{2,1,1}\\; b_{2,2,1}\\; b_{2,3,1}\n",
    "\\end{pmatrix}\n",
    ",\n",
    "\\begin{pmatrix}\n",
    "b_{1,1,2}\\; b_{1,2,2}\\; b_{1,3,2}\\\\\n",
    "b_{2,1,2}\\; b_{2,2,2}\\; b_{2,3,2}\n",
    "\\end{pmatrix}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "$$C = A \\cdot B$$\n",
    "\n",
    "$$\\begin{aligned}\n",
    "C = \\begin{pmatrix}\n",
    "a_{1,1,1}\\; x \\; b_{1,1,1}\\; a_{1,2,1}\\; x \\; b_{1,2,1}\\; a_{1,3,1}\\; x \\; b_{1,3,1}\\\\\n",
    "a_{2,1,1}\\; x \\; b_{2,1,1}\\; a_{2,2,1}\\; x \\; b_{2,2,1}\\; a_{2,3,1}\\; x \\; b_{2,3,1}\n",
    "\\end{pmatrix}\n",
    ",\n",
    "\\begin{pmatrix}\n",
    "a_{1,1,2}\\; x \\; b_{1,1,2}\\; a_{1,2,2}\\; x \\; b_{1,2,2}\\; a_{1,3,2}\\; x \\; b_{1,3,2}\\\\\n",
    "a_{2,1,2}\\; x \\; b_{2,1,2}\\; a_{2,2,2}\\; x \\; b_{2,2,2}\\; a_{2,3,2}\\; x \\; b_{2,3,2}\n",
    "\\end{pmatrix}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "In NumPy, we can multiply tensors directly by multiplying arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "painted-breathing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  1   4   9]\n",
      "  [ 16  25  36]\n",
      "  [ 49  64  81]]\n",
      "\n",
      " [[121 144 169]\n",
      "  [196 225 256]\n",
      "  [289 324 361]]\n",
      "\n",
      " [[441 484 529]\n",
      "  [576 625 676]\n",
      "  [729 784 841]]]\n"
     ]
    }
   ],
   "source": [
    "# tensor Hadamard product\n",
    "from numpy import array\n",
    "\n",
    "# define first tensor\n",
    "A = array([\n",
    "[[1,2,3], [4,5,6], [7,8,9]],\n",
    "[[11,12,13], [14,15,16], [17,18,19]],\n",
    "[[21,22,23], [24,25,26], [27,28,29]]])\n",
    "\n",
    "# define second tensor\n",
    "B = array([\n",
    "[[1,2,3], [4,5,6], [7,8,9]],\n",
    "[[11,12,13], [14,15,16], [17,18,19]],\n",
    "[[21,22,23], [24,25,26], [27,28,29]]])\n",
    "\n",
    "# multiply tensors\n",
    "C = A * B\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriental-ordinary",
   "metadata": {},
   "source": [
    "### Tensor Division\n",
    "\n",
    "The element-wise division of one tensor with another tensor with the same dimensions results in a new tensor with the same dimensions where each scalar value is the element-wise division of the scalars in the parent tensors.\n",
    "\n",
    "$$\\begin{aligned}\n",
    "A = \\begin{pmatrix}\n",
    "a_{1,1,1}\\; a_{1,2,1}\\; a_{1,3,1}\\\\\n",
    "a_{2,1,1}\\; a_{2,2,1}\\; a_{2,3,1}\n",
    "\\end{pmatrix}\n",
    ",\n",
    "\\begin{pmatrix}\n",
    "a_{1,1,2}\\; a_{1,2,2}\\; a_{1,3,2}\\\\\n",
    "a_{2,1,2}\\; a_{2,2,2}\\; a_{2,3,2}\n",
    "\\end{pmatrix}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "$$\\begin{aligned}\n",
    "B = \\begin{pmatrix}\n",
    "b_{1,1,1}\\; b_{1,2,1}\\; b_{1,3,1}\\\\\n",
    "b_{2,1,1}\\; b_{2,2,1}\\; b_{2,3,1}\n",
    "\\end{pmatrix}\n",
    ",\n",
    "\\begin{pmatrix}\n",
    "b_{1,1,2}\\; b_{1,2,2}\\; b_{1,3,2}\\\\\n",
    "b_{2,1,2}\\; b_{2,2,2}\\; b_{2,3,2}\n",
    "\\end{pmatrix}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "$$ C = \\frac{A}{B}$$\n",
    "\n",
    "$$\\begin{aligned}\n",
    "C = \\begin{pmatrix}\n",
    "\\frac{a_{1,1,1}}{ b_{1,1,1}}\\; \\frac{a_{1,2,1}}{ b_{1,2,1}}\\; \\frac{a_{1,3,1}}{ b_{1,3,1}}\\\\\n",
    "\\frac{a_{2,1,1}}{ b_{2,1,1}}\\; \\frac{a_{2,2,1}}{ b_{2,2,1}}\\; \\frac{a_{2,3,1}}{ b_{2,3,1}}\n",
    "\\end{pmatrix}\n",
    ",\n",
    "\\begin{pmatrix}\n",
    "\\frac{a_{1,1,2}}{ b_{1,1,2}}\\; \\frac{a_{1,2,2}}{ b_{1,2,2}}\\; \\frac{a_{1,3,2}}{ b_{1,3,2}}\\\\\n",
    "\\frac{a_{2,1,2}}{ b_{2,1,2}}\\; \\frac{a_{2,2,2}}{ b_{2,2,2}}\\; \\frac{a_{2,3,2}}{ b_{2,3,2}}\n",
    "\\end{pmatrix}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "least-polyester",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]]\n"
     ]
    }
   ],
   "source": [
    "# tensor division\n",
    "from numpy import array\n",
    "\n",
    "# define first tensor\n",
    "A = array([\n",
    "[[1,2,3], [4,5,6], [7,8,9]],\n",
    "[[11,12,13], [14,15,16], [17,18,19]],\n",
    "[[21,22,23], [24,25,26], [27,28,29]]])\n",
    "\n",
    "# define second tensor\n",
    "B = array([\n",
    "[[1,2,3], [4,5,6], [7,8,9]],\n",
    "[[11,12,13], [14,15,16], [17,18,19]],\n",
    "[[21,22,23], [24,25,26], [27,28,29]]])\n",
    "\n",
    "# divide tensors\n",
    "C = A / B\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "placed-gnome",
   "metadata": {},
   "source": [
    "## Tensor Product\n",
    "\n",
    "The tensor product operator is often denoted as a circle with a small x in the middle. We will denote it here as $\\bigotimes$ Given a tensor A with q dimensions and tensor B with r dimensions, the product of these tensors will be a new tensor with the order of q + r or, said another way, q + r dimensions. The tensor product is not limited to tensors, but can also be performed on matrices and vectors, which can be a good place to practice in order to develop the intuition for higher dimensions. Let's take a look at the tensor product for vectors.\n",
    "\n",
    "$$\\begin{aligned}\n",
    "a = \\begin{pmatrix}\n",
    "a_1\\\\\n",
    "a_2\n",
    "\\end{pmatrix}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "$$\n",
    "b = \\begin{pmatrix}\n",
    "b_1\\\\\n",
    "b_2\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "$$C = a\\bigotimes b$$\n",
    "\n",
    "$$\\begin{aligned}\n",
    "C = \\begin{pmatrix}\n",
    "a_1\\; x \\; \\begin{pmatrix}\n",
    "b_1\\\\\n",
    "b_2\n",
    "\\end{pmatrix}\\\\\n",
    "a_1\\; x \\; \\begin{pmatrix}\n",
    "b_1\\\\\n",
    "b_2\n",
    "\\end{pmatrix}\n",
    "\\end{pmatrix}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "or, unrolled:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "C = \\begin{pmatrix}\n",
    "a_1\\; x \\; b_1\\; \\; a_1\\; x \\; b_2\\\\\n",
    "a_2\\; x \\; b_1\\; \\; a_2\\; x \\; b_2\n",
    "\\end{pmatrix}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Let's take a look at the tensor product for matrices.\n",
    "\n",
    "$$\\begin{aligned}\n",
    "A = \\begin{pmatrix}\n",
    "a_{1,1}\\; a_{1,2}\\\\\n",
    "a_{2,1}\\; a_{2,2}\n",
    "\\end{pmatrix}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "$$\\begin{aligned}\n",
    "B = \\begin{pmatrix}\n",
    "b_{1,1}\\; b_{1,2}\\\\\n",
    "b_{2,1}\\; b_{2,2}\n",
    "\\end{pmatrix}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "$$C = a\\bigotimes b$$\n",
    "\n",
    "$$\\begin{aligned}\n",
    "C = \\begin{pmatrix}\n",
    "a_{1,1}\\; x\\;\\begin{pmatrix}\n",
    "b_{1,1}\\; b_{1,2}\\\\\n",
    "b_{2,1}\\; b_{2,2}\n",
    "\\end{pmatrix}\\; a_{1,2}\\; x\\;\\begin{pmatrix}\n",
    "b_{1,1}\\; b_{1,2}\\\\\n",
    "b_{2,1}\\; b_{2,2}\n",
    "\\end{pmatrix}\\\\\n",
    "a_{2,1}\\; x\\;\\begin{pmatrix}\n",
    "b_{1,1}\\; b_{1,2}\\\\\n",
    "b_{2,1}\\; b_{2,2}\n",
    "\\end{pmatrix}\\; a_{2,2}\\; x\\;\\begin{pmatrix}\n",
    "b_{1,1}\\; b_{1,2}\\\\\n",
    "b_{2,1}\\; b_{2,2}\n",
    "\\end{pmatrix}\n",
    "\\end{pmatrix}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Or, unrolled:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "C = \\begin{pmatrix}\n",
    "a_{1,1} \\; x\\; b_{1,1}\\;\\;\\; a_{1,1} \\; x\\; b_{1,2}\\;\\;\\; a_{1,2} \\; x\\; b_{1,1}\\;\\;\\; a_{1,2} \\; x\\; b_{1,2}\\\\\n",
    "a_{1,1} \\; x\\; b_{2,1}\\;\\;\\; a_{1,1} \\; x\\; b_{2,2}\\;\\;\\; a_{1,2} \\; x\\; b_{2,1}\\;\\;\\; a_{1,2} \\; x\\; b_{2,2}\\\\\n",
    "a_{2,1} \\; x\\; b_{1,1}\\;\\;\\; a_{2,1} \\; x\\; b_{1,2}\\;\\;\\; a_{2,2} \\; x\\; b_{1,1}\\;\\;\\; a_{2,2} \\; x\\; b_{1,2}\\\\\n",
    "a_{2,1} \\; x\\; b_{2,1}\\;\\;\\; a_{2,1} \\; x\\; b_{2,2}\\;\\;\\; a_{2,2} \\; x\\; b_{2,1}\\;\\;\\; a_{2,2} \\; x\\; b_{2,2}\n",
    "\\end{pmatrix}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "The tensor product can be implemented in NumPy using the **tensordot()** function. The function takes as arguments the two tensors to be multiplied and the axis on which to sum the products over, called the sum reduction. To calculate the tensor product, also called the tensor dot product in NumPy, the axis must be set to 0. In the example below, we define two order-1 tensors (vectors) with and calculate the tensor product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acute-jenny",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 4]\n",
      " [6 8]]\n"
     ]
    }
   ],
   "source": [
    "# tensor product\n",
    "from numpy import array\n",
    "from numpy import tensordot\n",
    "\n",
    "# define first vector\n",
    "A = array([1,2])\n",
    "\n",
    "# define second vector\n",
    "B = array([3,4])\n",
    "\n",
    "# calculate tensor product\n",
    "C = tensordot(A, B, axes=0)\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instructional-parish",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
